{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf sentence-transformers transformers torch\n"
      ],
      "metadata": {
        "id": "Eo8KlxnplWXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBlTIOSIlR2c",
        "outputId": "ea9afbbf-758a-47bd-dbf2-bd10d21d33de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "gemini_key= userdata.get('Gemini')"
      ],
      "metadata": {
        "id": "tzRGfvkPqnkY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "#Extract Text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page_num in range(doc.page_count):\n",
        "        page = doc.load_page(page_num)\n",
        "        text += page.get_text(\"text\")\n",
        "    doc.close()\n",
        "    return text\n",
        "\n",
        "#Chunk the extracted text\n",
        "def chunk_text(text, chunk_size=500):\n",
        "    sentences = text.split('. ')\n",
        "    chunks = [' '.join(sentences[i:i+chunk_size]) for i in range(0, len(sentences), chunk_size)]\n",
        "    return chunks\n",
        "\n",
        "# Rerank the chunks based on the query (top 3)\n",
        "def retrieve_relevant_chunks(query, text_chunks, chunk_embeddings, model):\n",
        "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "    similarity_scores = util.pytorch_cos_sim(query_embedding, chunk_embeddings)\n",
        "    top_chunk_indices = torch.argsort(similarity_scores, descending=True).squeeze()\n",
        "    top_chunks = [text_chunks[i] for i in top_chunk_indices[:3]]\n",
        "    return top_chunks\n",
        "\n",
        "def generate_response_google_gemini(query, retrieved_chunks):\n",
        "    context = \" \".join(retrieved_chunks)\n",
        "    prompt = query + \" \" + context\n",
        "\n",
        "    response = call_google_gemini_api(prompt)\n",
        "    return response\n",
        "\n",
        "def call_google_gemini_api(prompt):\n",
        "    import requests\n",
        "\n",
        "    api_url = \"https://api.google.com/gemini/generate\"\n",
        "    headers = {\"Authorization\": gemini_key}\n",
        "    data = {\"prompt\": prompt}\n",
        "\n",
        "    response = requests.post(api_url, headers=headers, json=data)\n",
        "\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()['text']\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}, {response.text}\")\n",
        "        return \"Error generating response\""
      ],
      "metadata": {
        "id": "ra7HfboKvpVJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pdf_path = '/content/drive/My Drive/Capstone/basics_of_strength_and_conditioning_manual.pdf'  # Update with your PDF path\n",
        "\n",
        "# Extract and chunk the PDF text\n",
        "pdf_text = extract_text_from_pdf(pdf_path)\n",
        "text_chunks = chunk_text(pdf_text, chunk_size=5)\n",
        "\n",
        "#  pre-trained sentence transformer model for embedding\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # A compact and efficient transformer\n",
        "\n",
        "# Embed  text chunks\n",
        "chunk_embeddings = embedding_model.encode(text_chunks, convert_to_tensor=True)\n",
        "\n",
        "query = \"What exercises are recommended for cardiovascular health?\"\n",
        "\n",
        "# Retrieve relevant chunks based on the query\n",
        "top_chunks = retrieve_relevant_chunks(query, text_chunks, chunk_embeddings, embedding_model)\n",
        "\n",
        "# Generate a response\n",
        "response = generate_response_google_gemini(query, top_chunks)\n",
        "\n",
        "# Output\n",
        "print(\"Generated Response from Google Gemini:\")\n",
        "print(response)\n",
        "\n",
        "output_text_path = '/content/drive/My Drive/Capstone/extracted_text.txt'\n",
        "with open(output_text_path, 'w', encoding='utf-8') as text_file:\n",
        "    text_file.write(pdf_text)\n",
        "\n",
        "print(f\"Text data has been saved to {output_text_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELhK0hpVpO4a",
        "outputId": "6a202a16-8c7a-4129-97b7-1bcbdcbadca9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 404, <!DOCTYPE html>\n",
            "<html lang=en>\n",
            "  <meta charset=utf-8>\n",
            "  <meta name=viewport content=\"initial-scale=1, minimum-scale=1, width=device-width\">\n",
            "  <title>Error 404 (Not Found)!!1</title>\n",
            "  <style>\n",
            "    *{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/branding/googlelogo/1x/googlelogo_color_150x54dp.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}\n",
            "  </style>\n",
            "  <a href=//www.google.com/><span id=logo aria-label=Google></span></a>\n",
            "  <p><b>404.</b> <ins>That’s an error.</ins>\n",
            "  <p>The requested URL <code>/gemini/generate</code> was not found on this server.  <ins>That’s all we know.</ins>\n",
            "\n",
            "Generated Response from Google Gemini:\n",
            "Error generating response\n",
            "Text data has been saved to /content/drive/My Drive/Capstone/extracted_text.txt\n"
          ]
        }
      ]
    }
  ]
}