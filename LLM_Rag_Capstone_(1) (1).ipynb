{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn5l2Kq1R8Zj",
        "outputId": "d2dfc363-7ad7-477a-a4ba-fb2820d979a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.6/326.6 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q pymupdf sentence-transformers transformers torch faiss-cpu openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "import openai\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import textwrap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZP2TagUSAvY",
        "outputId": "ab8729a9-2bb4-49b7-9f78-1ebacb10f0cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# API key from colab secrets (if you run in local environment you will need different methodology this is for colab only. Typically API key is stored in environment variable)\n",
        "from google.colab import drive, userdata\n",
        "drive.mount('/content/drive')\n",
        "openai.api_key = userdata.get('ChatGPT')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kq5Shr7MSD03",
        "outputId": "a95d4e9f-42c6-4540-bf44-365fb7b4ca30"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path, start_page=0, end_page=None):\n",
        "    pdf_document = fitz.open(pdf_path)\n",
        "\n",
        "    if end_page is None:\n",
        "        end_page = pdf_document.page_count - 1\n",
        "\n",
        "    extracted_text = \"\"\n",
        "\n",
        "    for page_num in range(start_page, end_page + 1):\n",
        "        page = pdf_document.load_page(page_num)\n",
        "        extracted_text += page.get_text(\"text\")\n",
        "\n",
        "    pdf_document.close()\n",
        "    return extracted_text\n",
        "\n",
        "\n",
        "# Function to chunk the extracted text\n",
        "def chunk_text(text):\n",
        "    paragraphs = text.split('\\n\\n')\n",
        "    return paragraphs\n",
        "\n",
        "# doc retrieval and reranking function\n",
        "def retrieve_and_rerank_documents(query, documents, embedding_model, cross_encoder_model, cross_encoder_tokenizer, top_k=3):\n",
        "    # doc encoding\n",
        "    doc_embeddings = embedding_model.encode(documents, normalize_embeddings=True)\n",
        "    query_embedding = embedding_model.encode(query, normalize_embeddings=True)\n",
        "\n",
        "    # FAISS similarity search (Facebook AI Similarity Search)\n",
        "    dimension = doc_embeddings.shape[1]\n",
        "    faiss_index = faiss.IndexFlatL2(dimension)\n",
        "    faiss_index.add(doc_embeddings)\n",
        "    distances, indices = faiss_index.search(np.expand_dims(query_embedding, axis=0), top_k * 5)  # Retrieve more for re-ranking\n",
        "\n",
        "    # top documents\n",
        "    retrieved_docs = [documents[idx] for idx in indices.flatten()]\n",
        "\n",
        "    # Cross-encoder reranking\n",
        "    inputs = cross_encoder_tokenizer(\n",
        "        [query] * len(retrieved_docs),\n",
        "        retrieved_docs,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        scores = cross_encoder_model(**inputs).logits.squeeze()\n",
        "\n",
        "    # top indices\n",
        "    top_indices = torch.topk(scores, k=top_k).indices.tolist()\n",
        "    most_similar_documents = [retrieved_docs[idx] for idx in top_indices]\n",
        "\n",
        "    return most_similar_documents\n",
        "\n",
        "# response generatio n function\n",
        "def generate_response_chatgpt(prompt, model=\"gpt-4\"):\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=400,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "IY5i4sKWSIor"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    pdf_path = '/content/drive/My Drive/Capstone/basics_of_strength_and_conditioning_manual.pdf'\n",
        "\n",
        "    # Specify the range of pages\n",
        "    start_page = 48\n",
        "    end_page = 49\n",
        "\n",
        "    pdf_text = extract_text_from_pdf(pdf_path, start_page, end_page)\n",
        "\n",
        "    # Load pre-trained sentence transformer model for embedding\n",
        "    embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "    # Load cross-encoder model for re-ranking\n",
        "    cross_encoder_model = AutoModelForSequenceClassification.from_pretrained(\"cross-encoder/ms-marco-MiniLM-L-12-v2\")\n",
        "    cross_encoder_tokenizer = AutoTokenizer.from_pretrained(\"cross-encoder/ms-marco-MiniLM-L-12-v2\")\n",
        "\n",
        "    # Query\n",
        "    query = \"I'm really having a hard time with my squats, how can I improve?\"\n",
        "\n",
        "    # Retrieve and re-rank documents\n",
        "    most_similar_documents = retrieve_and_rerank_documents(\n",
        "        query,\n",
        "        text_chunks,\n",
        "        embedding_model,\n",
        "        cross_encoder_model,\n",
        "        cross_encoder_tokenizer,\n",
        "        top_k=3\n",
        "    )\n",
        "\n",
        "    # Prompt\n",
        "    CONTEXT = \"\"\n",
        "    for doc in most_similar_documents:\n",
        "        wrapped_text = textwrap.fill(doc, width=100)\n",
        "        CONTEXT += wrapped_text + \"\\n\\n\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Assume the role of a physical trainer or athletics coach, giving short a short phrase of positive encouragement if the user expresses negative sentiment.\n",
        "    Be sure to do more than just provide positive encouragement and include a short response using the following CONTEXT to answer the QUESTION at the end.\n",
        "    If you don't know the answer, just say that you don't know; don't try to make up an answer.\"\n",
        "\n",
        "    CONTEXT:\n",
        "    {CONTEXT}\n",
        "    QUESTION: {query}\n",
        "    \"\"\"\n",
        "\n",
        "    response = generate_response_chatgpt(prompt)\n",
        "\n",
        "    print(\"Generated Response:\")\n",
        "    print(response)\n",
        "\n",
        "    # -> save pdf extracted text\n",
        "    output_text_path = '/content/drive/My Drive/Capstone/extracted_text.txt'\n",
        "    with open(output_text_path, 'w', encoding='utf-8') as text_file:\n",
        "        text_file.write(pdf_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOOAZbp-SUU7",
        "outputId": "db36664c-8bd7-424b-d988-04e4dc2878a6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Response:\n",
            "Keep going, progress takes time! The key to improving squats is focusing on form and technique, as mentioned in the manual. Make sure you're properly positioned under the bar, engaging your core, and maintaining the correct torso angle throughout the lift. Also, remember to breathe properly - inhale deeply before starting your descent, and exhale at or near the top of the squat. Try incorporating a variety of abdominal exercises into your routine as well, as strong abdominals help maintain torso stability during the squat. Keep at it, you're doing great!\n"
          ]
        }
      ]
    }
  ]
}